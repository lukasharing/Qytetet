{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Colab",
      "provenance": [],
      "collapsed_sections": [
        "Gm_aEYocjJ7g"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIbb1NS3i4iV",
        "colab_type": "text"
      },
      "source": [
        "# Práctica 2 - Visión por Computador"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppVTwfFQiViT",
        "colab_type": "text"
      },
      "source": [
        "## Import all libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZomzLWsJoWM9",
        "colab_type": "text"
      },
      "source": [
        "### Importar Genérico"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Np-mXuTTidYc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import NumPy\n",
        "import  numpy  as np\n",
        "# Import Plot\n",
        "import  matplotlib.pyplot as plt\n",
        "\n",
        "# Import Enumerators\n",
        "import enum\n",
        "\n",
        "# Keras Imports\n",
        "import keras\n",
        "import keras.utils as  np_utils\n",
        "\n",
        "# Import Image Processing Keras\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "\n",
        "# Import Keras Sequential Model\n",
        "from keras.models import Sequential\n",
        "\n",
        "# Import Keras Convolutional Layers\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
        "\n",
        "# Import Keras Common Layers\n",
        "from keras.layers import Activation, Dense, Dropout, Flatten, BatchNormalization\n",
        "\n",
        "# Import Keras Image Generators (IGenerator)\n",
        "from keras.preprocessing.image import ImageDataGenerator  \n",
        "\n",
        "# Import Keras Optimizers\n",
        "from keras.optimizers  import  SGD\n",
        "\n",
        "# Import Keras Callbacks\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "# Import Cifar Dataset\n",
        "from keras.datasets  import  cifar100\n",
        "\n",
        "# Import ResNet50 \n",
        "from keras.applications.resnet50 import ResNet50\n",
        "\n",
        "# Import InceptionResNetV2\n",
        "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
        "\n",
        "DEBUG = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8-_i8p3oRjs",
        "colab_type": "text"
      },
      "source": [
        "### Importar Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vk4SH2HaEFq5",
        "colab_type": "code",
        "outputId": "2f853a77-6cc7-4a0e-fd6c-bb1d288952c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Import Google Drive Library\n",
        "from google.colab import drive\n",
        "# Mount in the colab fs our google drive\n",
        "drive.mount(\"/content/drive\", force_remount = True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YL6p_8l-rvZf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Zip Path\n",
        "file_name = \"CUB-200\"\n",
        "zip_path = \"/content/drive/My Drive/VC/\"+ file_name +\".zip\"\n",
        "# Mount Path (best way temp folder so we dont loose drive's space)\n",
        "to_path=\"/tmp\"\n",
        "# Remove if we want to rebuild\n",
        "!rm -rf \"$to_path\"\n",
        "# Unzip into the \"mount path\"\n",
        "!unzip -q \"$zip_path\" -d \"$to_path\"\n",
        "# Rename with the created folder\n",
        "to_path = to_path + \"/\" + file_name"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAj9Sn21ix8f",
        "colab_type": "text"
      },
      "source": [
        "## Cargar Imágenes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyKzmx9CqvXV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ILoader(enum.Enum):\n",
        "   CIFAR  = 0\n",
        "   CALTECH = 1\n",
        "\n",
        "def load_dataset(iload_type = ILoader.CIFAR):\n",
        "\n",
        "  print(\"--- Loading Dataset ---\")\n",
        "\n",
        "  data_set = \"\"\n",
        "\n",
        "  value = int(iload_type.value)\n",
        "\n",
        "  if   value == int(ILoader.CIFAR.value)   : data_set = load_cifar_dataset()\n",
        "  elif value == int(ILoader.CALTECH.value) : data_set = load_caltech_dataset(to_path)\n",
        "  \n",
        "  return data_set\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SCbhIJFnp2t",
        "colab_type": "text"
      },
      "source": [
        "### Cargar CIFAR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYPh61FdisDZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_cifar_dataset():\n",
        "\n",
        "  (x_train, y_train), (x_test, y_test) = cifar100.load_data(label_mode='fine')\n",
        "  x_train = x_train.astype('float32')\n",
        "  x_test = x_test.astype('float32')\n",
        "  \n",
        "  x_train /= 255\n",
        "  x_test  /= 255\n",
        "  \n",
        "  train_idx = np.isin(y_train, np.arange(25))\n",
        "  train_idx = np.reshape(train_idx, -1)\n",
        "  x_train = x_train[train_idx]\n",
        "  y_train = y_train[train_idx]\n",
        "  \n",
        "  test_idx = np.isin(y_test , np.arange(25))\n",
        "  test_idx = np.reshape(test_idx, -1)\n",
        "  x_test = x_test[test_idx]\n",
        "  y_test = y_test[test_idx]\n",
        "\n",
        "  y_train = np_utils.to_categorical(y_train, 25)\n",
        "  y_test = np_utils.to_categorical(y_test, 25)\n",
        "  \n",
        "  return  x_train, y_train, x_test, y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5kjYGc9nthK",
        "colab_type": "text"
      },
      "source": [
        "### Cargar Caltech-UCSD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HTSE2gnnwZy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def read_images(vec_imagenes, path):\n",
        "  clases = np.array([img.split('/')[0] for img in vec_imagenes])\n",
        "  imagenes = np.array([\n",
        "    img_to_array(\n",
        "      load_img(\n",
        "        path + \"/\" + img, \n",
        "        target_size = (224, 224),\n",
        "        interpolation = 'nearest'\n",
        "      )\n",
        "    ) for img in vec_imagenes\n",
        "  ])\n",
        "  return imagenes, clases\n",
        "\n",
        "def load_caltech_dataset(path):\n",
        "  train_images = np.loadtxt(path + \"/train.txt\", dtype = str)\n",
        "  test_images = np.loadtxt(path + \"/test.txt\", dtype = str)\n",
        "\n",
        "  x_train, y_train = read_images(train_images, path + \"/images\")\n",
        "  x_test, y_test = read_images(test_images, path + \"/images\")\n",
        "  \n",
        "  clases_posibles = np.unique(np.copy(y_train))\n",
        "  for i in range(len(clases_posibles)):\n",
        "    y_train[y_train == clases_posibles[i]] = i\n",
        "    y_test[y_test == clases_posibles[i]] = i\n",
        "\n",
        "  y_train = np_utils.to_categorical(y_train, 200)\n",
        "  y_test = np_utils.to_categorical(y_test, 200)\n",
        "  \n",
        "  train_perm = np.random.permutation(len(x_train))\n",
        "  x_train = x_train[train_perm]\n",
        "  y_train = y_train[train_perm]\n",
        "\n",
        "  test_perm = np.random.permutation(len(x_test))\n",
        "  x_test = x_test[test_perm]\n",
        "  y_test = y_test[test_perm]\n",
        "  \n",
        "  return x_train, y_train, x_test, y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gm_aEYocjJ7g",
        "colab_type": "text"
      },
      "source": [
        "## Evolución"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92IBcp0xjI12",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def  show_evolution(hist):\n",
        "  loss = hist.history['loss']\n",
        "  val_loss = hist.history['val_loss']\n",
        "  plt.plot(loss)\n",
        "  plt.plot(val_loss)\n",
        "  plt.legend(['Training  loss', 'Validation  loss'])\n",
        "  plt.show()\n",
        "\n",
        "  acc = hist.history['acc']\n",
        "  val_acc = hist.history['val_acc']\n",
        "  plt.plot(acc)\n",
        "  plt.plot(val_acc)\n",
        "  plt.legend(['Training  accuracy','Validation  accuracy'])\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLs6-TPfjVNy",
        "colab_type": "text"
      },
      "source": [
        "## Modelos\n",
        "\n",
        "Hablar sobre las escalas (características)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFRiWSLYjYoe",
        "colab_type": "text"
      },
      "source": [
        "### Modelo Práctica 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxCIXWbojSsC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def BaseNet():\n",
        "  return Sequential([\n",
        "    # 5 Kernel = 4 + 1 ( central ) = 2 (left/right, top/bottom)\n",
        "    # 32 - 2 (left/bottom) - 2 (right/top) = 28\n",
        "    # Input Image 32 x 32 x 3\n",
        "    Conv2D(6, kernel_size = (5, 5), input_shape = (32, 32, 3)),\n",
        "    \n",
        "    Activation(\"relu\"),\n",
        "    \n",
        "    # 28 / 2 = 14\n",
        "    MaxPooling2D(pool_size = (2, 2), strides = (2, 2)),\n",
        "    \n",
        "    # 14 - 2 (left/bottom) - 2 (right/top) = 10\n",
        "    Conv2D(16, kernel_size = (5, 5)),\n",
        "    \n",
        "    Activation(\"relu\"),\n",
        "    \n",
        "    # 10 / 2 = 5\n",
        "    MaxPooling2D(pool_size = (2, 2), strides = (2, 2)),\n",
        "    \n",
        "    # Aplanar antes de pasarlo por las capas dense\n",
        "    Flatten(),\n",
        "\n",
        "    # Input 400, output 50\n",
        "    Dense(units = 50, input_shape = (400,)),\n",
        "    \n",
        "    Activation(\"relu\"),\n",
        "    \n",
        "    Dense(units = 25, input_shape = (50,)),\n",
        "\n",
        "    Activation(\"softmax\")\n",
        "  ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUYy5V3zKF1e",
        "colab_type": "text"
      },
      "source": [
        "### Modelo Práctica 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90f8YyENN053",
        "colab_type": "text"
      },
      "source": [
        "#### Modelo BatchNormalization Antes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhdA1TFJKE6p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def BaseNetBatchBefore():\n",
        "  return Sequential([\n",
        "    # 5 Kernel = 4 + 1 ( central ) = 2 (left/right, top/bottom)\n",
        "    # 32 - 2 (left/bottom) - 2 (right/top) = 28\n",
        "    # Input Image 32 x 32 x 3\n",
        "    Conv2D(6, kernel_size = (5, 5), input_shape = (32, 32, 3)),\n",
        "    BatchNormalization(),\n",
        "    Activation(\"relu\"),\n",
        "    \n",
        "    # 28 / 2 = 14\n",
        "    MaxPooling2D(pool_size = (2, 2), strides = (2, 2)),\n",
        "    \n",
        "    # 14 - 2 (left/bottom) - 2 (right/top) = 10\n",
        "    Conv2D(16, kernel_size = (5, 5)),\n",
        "    BatchNormalization(),\n",
        "    Activation(\"relu\"),\n",
        "    \n",
        "    # 10 / 2 = 5\n",
        "    MaxPooling2D(pool_size = (2, 2), strides = (2, 2)),\n",
        "    \n",
        "    # Aplanar antes de pasarlo por las capas dense\n",
        "    Flatten(),\n",
        "\n",
        "    # Input 400, output 50\n",
        "    Dense(units = 50, input_shape = (400,)),\n",
        "    \n",
        "    Activation(\"relu\"),\n",
        "    \n",
        "    Dense(units = 25, input_shape = (50,)),\n",
        "\n",
        "    Activation(\"softmax\")\n",
        "  ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xigBqtcKN828",
        "colab_type": "text"
      },
      "source": [
        "#### Modelo BatchNormalization Después"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohpFmt0QN635",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def BaseNetBatchAfter():\n",
        "  return Sequential([\n",
        "    # 5 Kernel = 4 + 1 ( central ) = 2 (left/right, top/bottom)\n",
        "    # 32 - 2 (left/bottom) - 2 (right/top) = 28\n",
        "    # Input Image 32 x 32 x 3\n",
        "    Conv2D(6, kernel_size = (5, 5), input_shape = (32, 32, 3)),\n",
        "    Activation(\"relu\"),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    # 28 / 2 = 14\n",
        "    MaxPooling2D(pool_size = (2, 2), strides = (2, 2)),\n",
        "    \n",
        "    # 14 - 2 (left/bottom) - 2 (right/top) = 10\n",
        "    Conv2D(16, kernel_size = (5, 5)),\n",
        "    Activation(\"relu\"),\n",
        "    BatchNormalization(),\n",
        "    \n",
        "    # 10 / 2 = 5\n",
        "    MaxPooling2D(pool_size = (2, 2), strides = (2, 2)),\n",
        "    \n",
        "    # Aplanar antes de pasarlo por las capas dense\n",
        "    Flatten(),\n",
        "\n",
        "    # Input 400, output 50\n",
        "    Dense(units = 50, input_shape = (400,)),\n",
        "    Activation(\"relu\"),\n",
        "\n",
        "    Dense(units = 25, input_shape = (50,)),\n",
        "    Activation(\"softmax\")\n",
        "  ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjRCBjtiOOQq",
        "colab_type": "text"
      },
      "source": [
        "#### Modelo Optimizado"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYgLo4ECOM0j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def BaseNetBatchOptimized():\n",
        "  return Sequential([\n",
        "    # 5 Kernel = 4 + 1 ( central ) = 2 (left/right, top/bottom)\n",
        "    # Input Image 32 x 32 x 3\n",
        "    # 32 - 3 (left/bottom) - 3 (right/top) = 26\n",
        "    Conv2D(16, kernel_size = (3, 3), input_shape = (32, 32, 3)),\n",
        "    Activation(\"relu\"),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    # 26 - 2 (left/bottom) - 2 (right/top) = 22\n",
        "    Conv2D(32, kernel_size = (3, 3)),\n",
        "    Activation(\"relu\"),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    # 26 / 2 = 11\n",
        "    MaxPooling2D(pool_size = (2, 2), strides = (2, 2)),\n",
        "    \n",
        "    # 11 - 2 (left/bottom) - 1 (right/top) = 9\n",
        "    Conv2D(64, kernel_size = (3, 3)),\n",
        "    Activation(\"relu\"),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    # 13 - 1 (left/bottom) - 1 (right/top) = 11\n",
        "    Conv2D(128, kernel_size = (3, 3)),\n",
        "    Activation(\"relu\"),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    # 11 - 1 (left/bottom) - 1 (right/top) = 9\n",
        "    Conv2D(256, kernel_size = (3, 3)),\n",
        "    Activation(\"relu\"),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    # 11 / 2 = 5.5\n",
        "    MaxPooling2D(pool_size = (2, 2), strides = (2, 2)),\n",
        "    \n",
        "    # Aplanar antes de pasarlo por las capas dense\n",
        "    Flatten(),\n",
        "\n",
        "    # Input 400, output 50\n",
        "    Dense(units = 50, input_shape = (400,)),\n",
        "    Activation(\"relu\"),\n",
        "\n",
        "    Dense(units = 25, input_shape = (50,)),\n",
        "    Activation(\"softmax\")\n",
        "  ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcqIfR8CPU3o",
        "colab_type": "text"
      },
      "source": [
        "### ResNet50 Estractor de Características"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1Q4c5gTHvwu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ResNetExtractor():\n",
        "  # Create ResNet \n",
        "  Res50 = ResNet50(\n",
        "    weights = \"imagenet\", # Set Weights of imagenet\n",
        "    include_top = False, # Remove Last Layer\n",
        "    pooling = \"avg\", # Add Average Polling last layer\n",
        "    input_shape = (224, 224, 3) # Input shape and channels\n",
        "  )\n",
        "\n",
        "  # Set all layers to no trainable because we only want the characteristics\n",
        "  for layer in Res50.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "  # Create Net Characteristics Extractor\n",
        "  return Sequential([\n",
        "    Res50,\n",
        "\n",
        "    # Dense\n",
        "    Dense(500, input_shape = (2048,)),\n",
        "    Activation(\"relu\"),\n",
        "\n",
        "    # Dense of 200 characteristics\n",
        "    Dense(200, input_shape = (500,)),\n",
        "    Activation(\"softmax\")\n",
        "  ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLGonrP91_MY",
        "colab_type": "text"
      },
      "source": [
        "### ResNet50 Fine Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_-8vt342KN2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create Net Fine Tuning ( Difference: All Layers are trainable)\n",
        "def ResNetFineTuning():\n",
        "  return Sequential([\n",
        "    ResNet50(\n",
        "      weights = \"imagenet\", # Set Weights of imagenet\n",
        "      include_top = False, # Remove Last Layer\n",
        "      pooling = \"avg\", # Add Average Polling last layer\n",
        "      input_shape = (224, 224, 3) # Input shape and channels\n",
        "    ),\n",
        "\n",
        "    # Dense\n",
        "    Dense(500, input_shape = (2048,)),\n",
        "    Activation(\"relu\"),\n",
        "\n",
        "    # Dense of 200 characteristics\n",
        "    Dense(200, input_shape = (500,)),\n",
        "    Activation(\"softmax\")\n",
        "  ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASNYOV0-E0gF",
        "colab_type": "text"
      },
      "source": [
        "### InceptionResNetV2 (Bonus)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUV6dL8wFDpb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create \n",
        "def Inception():\n",
        "  return Sequential([\n",
        "    InceptionResNetV2(\n",
        "      weights = \"imagenet\", # Set Weights of imagenet\n",
        "      include_top = False, # Remove Last Layer\n",
        "      pooling = \"avg\", # Add Average Polling last layer\n",
        "      input_shape = (224, 224, 3) # Input shape and channels\n",
        "    ),\n",
        "    # Dense\n",
        "    Dense(1024, input_shape = (2048,)),\n",
        "    Activation(\"relu\"),\n",
        "    # Dense of 200 characteristics\n",
        "    Dense(200, input_shape = (1024,)),\n",
        "    Activation(\"softmax\")\n",
        "  ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sgCQPVpjuPa",
        "colab_type": "text"
      },
      "source": [
        "## Generadores de Imágenes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPohuTL6pe34",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class IGenerator(enum.Enum):\n",
        "   SIMPLE    = 0\n",
        "   COMPLEX   = 1\n",
        "   WHITENING = 2\n",
        "   RESNET    = 3\n",
        "   INCEPTION = 4\n",
        "\n",
        "\n",
        "def igenerator(igenerator_type = IGenerator.SIMPLE, split = 0.0):\n",
        "\n",
        "  generator = \"\"\n",
        "\n",
        "  value = int(igenerator_type.value)\n",
        "  if   value == int(IGenerator.SIMPLE.value)    : generator = IGenerator_simple(split)\n",
        "  elif value == int(IGenerator.COMPLEX.value)   : generator = IGenerator_complex(split)\n",
        "  elif value == int(IGenerator.WHITENING.value) : generator = IGenerator_whitening(split)\n",
        "  elif value == int(IGenerator.RESNET.value)    : generator = IGenerator_resnet(split)\n",
        "  elif value == int(IGenerator.INCEPTION.value) : generator = IGenerator_inception(split)\n",
        "  \n",
        "  return generator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLEssj0sj6eU",
        "colab_type": "text"
      },
      "source": [
        "### Generador Simple"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tA76d1ozjuyz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def IGenerator_simple(split = 0.0):\n",
        "  return ImageDataGenerator(\n",
        "    validation_split = split\n",
        "  )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQn_DCIrl6H3",
        "colab_type": "text"
      },
      "source": [
        "### Generador Mejorado"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUKSlQJFl8VD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def IGenerator_complex(split = 0.0):\n",
        "  return ImageDataGenerator(\n",
        "    validation_split = split,\n",
        "    featurewise_center = True,\n",
        "    featurewise_std_normalization = True,\n",
        "    horizontal_flip = True,\n",
        "    vertical_flip = True,\n",
        "    zoom_range = 0.2\n",
        "  )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRKPZ50VuQm5",
        "colab_type": "text"
      },
      "source": [
        "### Generador Whitening"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOSAHjTxuT2x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def IGenerator_whitening(split = 0.0):\n",
        "  return ImageDataGenerator(\n",
        "    validation_split = split,\n",
        "    featurewise_center = True,\n",
        "    featurewise_std_normalization = True,\n",
        "    zca_whitening = True\n",
        "  )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfEhTTIISf36",
        "colab_type": "text"
      },
      "source": [
        "#### Generador RESNET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLhKt_uLSiTs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def IGenerator_resnet(split = 0.0):\n",
        "  return ImageDataGenerator(\n",
        "    validation_split = split,\n",
        "    preprocessing_function = keras.applications.resnet50.preprocess_input\n",
        "  )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEEiPEPwGH-A",
        "colab_type": "text"
      },
      "source": [
        "#### Generador RESNET-INCEPTION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfwKmUSvGOxh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def IGenerator_inception(split = 0.0):\n",
        "  return ImageDataGenerator(\n",
        "    validation_split = split,\n",
        "    preprocessing_function = keras.applications.inception_resnet_v2.preprocess_input\n",
        "  )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hq14K4X5kzwP",
        "colab_type": "text"
      },
      "source": [
        "## Compiladores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdOZdejrlKoD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Compile(enum.Enum):\n",
        "   SGD = 0\n",
        "   ADAM = 1\n",
        "\n",
        "def compiler(model, compile_type = Compile.SGD):\n",
        "\n",
        "  optimizer = \"\"\n",
        "\n",
        "  value = int(compile_type.value)\n",
        "  if   value == int(Compile.SGD.value) : optimizer = sgd_optimizer() \n",
        "  elif value == int(Compile.ADAM.value): optimizer = adam_optimizer()\n",
        "\n",
        "  model.compile(\n",
        "    optimizer,\n",
        "    loss = \"categorical_crossentropy\",\n",
        "    metrics = [\"accuracy\"]\n",
        "  )\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-XGwEr1k17X",
        "colab_type": "text"
      },
      "source": [
        "### Optimizador SGD\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjF1klLuk3_u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sgd_optimizer():\n",
        "  return SGD(lr = 0.01, decay = 1e-6, momentum = 0.9, nesterov = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpVOe4vdk9As",
        "colab_type": "text"
      },
      "source": [
        "### <a href=\"https://arxiv.org/pdf/1712.07628.pdf\">Optimizador Adam</a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJSgvg23k-_3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def adam_optimizer():\n",
        "  return \"adam\";"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djYZAe3_n69O",
        "colab_type": "text"
      },
      "source": [
        "## Entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFAR6CDGo-Xb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TrainInfo(enum.Enum):\n",
        "   NONE = 0\n",
        "   FULL = 1\n",
        "   HALF = 2\n",
        "\n",
        "def train(model, batch_size = 32, epochs = 80, dataset = ILoader.CIFAR, info = TrainInfo.FULL, compile_type = Compile.SGD, igenerator_type = IGenerator.SIMPLE, early_stopping = False):\n",
        "  # Detail of the Information\n",
        "  verbose = int(info.value)\n",
        "\n",
        "  # Callbacks\n",
        "  callbacks = []  \n",
        "  \n",
        "  # Early Stopping Callback\n",
        "  if early_stopping:\n",
        "    callbacks.append(\n",
        "      EarlyStopping(\n",
        "        # Monitorize Val Loss\n",
        "        monitor  = 'val_loss',\n",
        "        # Patience (Minimum number of epochs at least trains)\n",
        "        patience = 10,\n",
        "        # Information Quantity\n",
        "        verbose  = verbose,\n",
        "      )\n",
        "    )\n",
        "  \n",
        "  # Load Dataset\n",
        "  x_train, y_train, x_test, y_test = load_dataset(dataset)\n",
        "\n",
        "  # Debug\n",
        "  if DEBUG: \n",
        "    debug(model, compile_type, igenerator_type, x_train, y_train)\n",
        "  \n",
        "  print(\"--- Training Model ---\")\n",
        "  # Compile Model\n",
        "  compiler(model, compile_type)\n",
        "  \n",
        "  # Obtain Generator, pass images and standarize (data augmentation)\n",
        "  generator_train = igenerator(\n",
        "    igenerator_type,\n",
        "    split = 0.1\n",
        "  )\n",
        "\n",
        "  # Asign to ram a size of x_train\n",
        "  generator_train.fit(x_train)\n",
        "  \n",
        "  # Fits the model on batches\n",
        "  history = model.fit_generator(\n",
        "    # Training Data Batch\n",
        "    generator = generator_train.flow(\n",
        "      x_train,\n",
        "      y_train,\n",
        "      batch_size = batch_size,\n",
        "      subset = \"training\"\n",
        "    ),\n",
        "    # Number of epochs (Times all batches will pass)\n",
        "    epochs = epochs,\n",
        "    # Number of batches for the training\n",
        "    steps_per_epoch = len(x_train) * 0.9 / batch_size,\n",
        "\n",
        "    # Validation Data Batch\n",
        "    validation_data = generator_train.flow(\n",
        "      x_train,\n",
        "      y_train,\n",
        "      batch_size = batch_size,\n",
        "      subset = \"validation\"\n",
        "    ),\n",
        "    # Number of batches for the testing\n",
        "    validation_steps = len(x_train) * 0.1 / batch_size,\n",
        "    # Appearance the info will show per bach\n",
        "    verbose = verbose,\n",
        "    # Callbacks (Early Stopping, etc.)\n",
        "    callbacks = callbacks\n",
        "  )\n",
        "\n",
        "  # Evaluate\n",
        "  evaluate(model, x_test, y_test, info, igenerator_type)\n",
        "\n",
        "  # Return Training History\n",
        "  return history\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCcxgS9sshcs",
        "colab_type": "text"
      },
      "source": [
        "## Evaluación"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deYUIg5Br9ic",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, x_test, y_test, info = TrainInfo.FULL, igenerator_type = IGenerator.SIMPLE):\n",
        "  # Detail of the Information\n",
        "  verbose = int(info.value)\n",
        "\n",
        "  print(\"--- Evaluate Results ---\")\n",
        "\n",
        "  # Test Generator\n",
        "  generator_test = igenerator(\n",
        "    igenerator_type\n",
        "  )\n",
        "\n",
        "  # Asign to ram  a size of x_test\n",
        "  generator_test.fit(x_test)\n",
        "\n",
        "  # Calc Accuracy\n",
        "  scores = model.evaluate_generator(\n",
        "    generator = generator_test.flow(\n",
        "      x_test,\n",
        "      y_test,\n",
        "      batch_size = 1,\n",
        "      shuffle = False\n",
        "    ),\n",
        "    # Appearance the info will show\n",
        "    steps = len(x_test),\n",
        "    verbose = verbose,\n",
        "  )\n",
        "\n",
        "  print(\"Accuracy: \", str(scores[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHxFptQ8skRX",
        "colab_type": "text"
      },
      "source": [
        "## Debug"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2WW7qB4smFa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def debug(model, compile_type, igenerator_type, x_train, y_train):\n",
        "  # Shows layer information of our model\n",
        "  print(\"Compiler  Type {}\".format(compile_type))\n",
        "  print(\"Generator Type {}\".format(igenerator_type))\n",
        "  model.summary()\n",
        "  \n",
        "  # Used for show nth images from the classes\n",
        "  rows = 5\n",
        "  cols = 5\n",
        "  for i in range(rows * cols):\n",
        "    plt.subplot(rows, cols, i + 1)\n",
        "    plt.imshow(x_train[i], cmap = 'gray', interpolation = 'none')\n",
        "    plt.title(\"Class  {}\".format(i))# y_train[i]\n",
        "\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itlgTxEjtW1Z",
        "colab_type": "text"
      },
      "source": [
        "## Tests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSbh31JZ28Ii",
        "colab_type": "text"
      },
      "source": [
        "## Ejercicios"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHsfm4T9ta0D",
        "colab_type": "text"
      },
      "source": [
        "### Ejercicio 1 \n",
        "\n",
        "Hay Overfitting (La gráfica de val_loss va creciendo)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBiceMu2AscS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# BaseNet\n",
        "history = train(\n",
        "  BaseNet(),\n",
        "  info = TrainInfo.HALF,\n",
        "  dataset = ILoader.CIFAR,\n",
        "  epochs = 30,\n",
        "  #early_stopping = True\n",
        ")\n",
        "\n",
        "show_evolution(history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9NYqcjGym8F",
        "colab_type": "text"
      },
      "source": [
        "### Ejercicio 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOQzJEPFBWyX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# BaseNet \n",
        "history = train(\n",
        "  BaseNetBatchOptimized(),\n",
        "  info = TrainInfo.FULL,\n",
        "  compile_type = Compile.SGD,\n",
        "  igenerator_type = IGenerator.COMPLEX,\n",
        "  epochs = 30,\n",
        "  #early_stopping = True\n",
        ")\n",
        "\n",
        "show_evolution(history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tu15un6lRaVT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# BaseNet Whitening\n",
        "history = train(\n",
        "  BaseNetBatchOptimized(),\n",
        "  info = TrainInfo.FULL,\n",
        "  compile_type = Compile.SGD,\n",
        "  igenerator_type = IGenerator.SIMPLE,\n",
        "  epochs = 30,\n",
        "  #early_stopping = True\n",
        ")\n",
        "\n",
        "show_evolution(history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75Omfcy0bmi2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# BaseNet Batch After\n",
        "history = train(\n",
        "  BaseNetBatchAfter(),\n",
        "  info = TrainInfo.FULL,\n",
        "  compile_type = Compile.SGD,\n",
        "  igenerator_type = IGenerator.COMPLEX,\n",
        "  epochs = 30,\n",
        "  #early_stopping = True\n",
        ")\n",
        "\n",
        "show_evolution(history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gc9MZdO7cQtv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# BaseNet Batch Before\n",
        "history = train(\n",
        "  BaseNetBatchBefore(),\n",
        "  info = TrainInfo.FULL,\n",
        "  compile_type = Compile.SGD,\n",
        "  igenerator_type = IGenerator.COMPLEX,\n",
        "  epochs = 30,\n",
        "  #early_stopping = True\n",
        ")\n",
        "\n",
        "show_evolution(history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhA9VW5u8tK3",
        "colab_type": "text"
      },
      "source": [
        "## Ejercicio 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHDjFjIxbtmm",
        "colab_type": "text"
      },
      "source": [
        "### Estractor de características"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4UVz0X48vtA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = train(\n",
        "  ResNetExtractor(),\n",
        "  dataset = ILoader.CALTECH,\n",
        "  igenerator_type = IGenerator.RESNET,\n",
        "  info = TrainInfo.HALF,\n",
        "  compile_type = Compile.SGD,\n",
        "  epochs = 15,\n",
        "  #early_stopping = True\n",
        ")\n",
        "\n",
        "show_evolution(history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fo8LxXj5b3uh",
        "colab_type": "text"
      },
      "source": [
        "### Fine Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0blTklKb1s8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = train(\n",
        "  ResNetFineTuning(),\n",
        "  dataset = ILoader.CALTECH,\n",
        "  igenerator_type = IGenerator.RESNET,\n",
        "  info = TrainInfo.HALF,\n",
        "  compile_type = Compile.SGD,\n",
        "  epochs = 15,\n",
        "  #early_stopping = True\n",
        ")\n",
        "\n",
        "show_evolution(history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YG_pzmaND_IB",
        "colab_type": "text"
      },
      "source": [
        "## Bonus\n",
        "https://medium.com/nanonets/how-to-easily-build-a-dog-breed-image-classification-model-2fd214419cde\n",
        "\n",
        "https://towardsdatascience.com/dog-breed-classification-hands-on-approach-b5e4f88c333e\n",
        "\n",
        "https://ai.googleblog.com/2016/08/improving-inception-and-image.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ey06yrDLD-Vv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = train(\n",
        "  Inception(),\n",
        "  dataset = ILoader.CALTECH,\n",
        "  igenerator_type = IGenerator.INCEPTION,\n",
        "  info = TrainInfo.HALF,\n",
        "  compile_type = Compile.SGD,\n",
        "  epochs = 10,\n",
        "  #early_stopping = True\n",
        ")\n",
        "\n",
        "show_evolution(history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9IrwsypOchb",
        "colab_type": "text"
      },
      "source": [
        "## Resumen\n",
        "\n",
        "| Model              | Compile | Generator | Epochs | Accuracy                 |\n",
        "|--------------------|---------|-----------|--------|--------------------------|\n",
        "| Normal             | SGD     | Simple    | 22     | t1: 0.4116               |\n",
        "| Optimized          | SGD     | Simple    | 80     | 0.5092                   |\n",
        "| Optimized          | ADAM    | Simple    | 80     | 0.498                    |\n",
        "| Optimized          | SGD     | Complex   | 80     | t1: 0.6016, t2: 0.5876   |\n",
        "| BaseNetBatchAfter  | SGD     | Simple    | 58     | t1: 0.488, t2:           |\n",
        "| BaseNetBatchBefore | SGD     | Simple    | 80/38  | t1: 0.4996, t2: 0.4868   |"
      ]
    }
  ]
}